Running from arcus-10
2019-05-12 04:09:42.577237: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-05-12 04:09:46.296174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: TITAN V major: 7 minor: 0 memoryClockRate(GHz): 1.455
pciBusID: 0000:82:00.0
totalMemory: 11.75GiB freeMemory: 11.34GiB
2019-05-12 04:09:46.296264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2019-05-12 04:09:46.872810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-05-12 04:09:46.872868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2019-05-12 04:09:46.872878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2019-05-12 04:09:46.873291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10955 MB memory) -> physical GPU (device: 0, name: TITAN V, pci bus id: 0000:82:00.0, compute capability: 7.0)
{'alpha': 0.9695127114884203, 'dropout': 0.12305510976720535, 'lr': 0.006589657941570796, 'leaky_relu': 0.014003889887698573, 'batch_norm': 0, 'loss_type': 'mse', 'num_layers': 3, 'layer_0': 378, 'layer_1': 362, 'layer_2': 32, 'layer_3': 383, 'layer_4': 193, 'layer_5': 167, 'layer_6': 361, 'layer_7': 99, 'max_concurrent': 3, 'P': 'arcus_gpu.p', 'q': 'arcus.q', 'l': "hostname='(arcus-1|arcus-2|arcus-3|arcus-4|arcus-5|arcus-6|arcus-7|arcus-8|arcus-9|arcus-10)'", 'env': '/home/jott1/Projects/SHERPA_EX/.profile', 'data': 'fluxbypass_aqua', 'run_type': 'hyper_param_opt_conservation', 'batch_size': 2048, 'data_dir': '/baldig/chemistry/earth_system_science/', 'max_dense_layers': 8, 'epochs': 100, 'patience': 10, 'conservation': 1}
Epoch 1/100
 - 3541s - loss: 311.4192 - val_loss: 250.7941
Epoch 2/100
 - 689s - loss: 264.7457 - val_loss: 243.0574
Epoch 3/100
 - 532s - loss: 254.8243 - val_loss: 230.3305
Epoch 4/100
 - 486s - loss: 248.8378 - val_loss: 222.3046
Epoch 5/100
 - 500s - loss: 247.9132 - val_loss: 234.5422
Epoch 6/100
 - 521s - loss: 244.5802 - val_loss: 221.1692
Epoch 7/100
 - 519s - loss: 241.8300 - val_loss: 222.8758
Epoch 8/100
 - 501s - loss: 241.6259 - val_loss: 230.4377
Epoch 9/100
 - 487s - loss: 239.9829 - val_loss: 223.9486
Epoch 10/100
 - 523s - loss: 240.7370 - val_loss: 228.4825
Epoch 11/100
 - 532s - loss: 239.2275 - val_loss: 223.0616
Epoch 12/100
 - 537s - loss: 237.7296 - val_loss: 220.5338
Epoch 13/100
 - 505s - loss: 239.4882 - val_loss: 284.3453
Epoch 14/100
 - 502s - loss: 237.1014 - val_loss: 222.9568
Epoch 15/100
 - 501s - loss: 236.1936 - val_loss: 218.5206
Epoch 16/100
 - 465s - loss: 236.3351 - val_loss: 221.5770
Epoch 17/100
 - 493s - loss: 235.7509 - val_loss: 224.3217
Epoch 18/100
 - 504s - loss: 235.8986 - val_loss: 255.1760
Epoch 19/100
 - 495s - loss: 235.0027 - val_loss: 216.8166
Epoch 20/100
 - 480s - loss: 234.6282 - val_loss: 238.4712
Epoch 21/100
 - 506s - loss: 234.6825 - val_loss: 213.0894
Epoch 22/100
 - 443s - loss: 234.4638 - val_loss: 227.3474
Epoch 23/100
 - 502s - loss: 234.5371 - val_loss: 214.4191
Epoch 24/100
 - 524s - loss: 235.0771 - val_loss: 212.4872
Epoch 25/100
 - 508s - loss: 234.0651 - val_loss: 208.8917
Epoch 26/100
 - 512s - loss: 233.1769 - val_loss: 219.2791
Epoch 27/100
 - 498s - loss: 233.7771 - val_loss: 214.8623
Epoch 28/100
 - 498s - loss: 234.0744 - val_loss: 217.6072
Epoch 29/100
 - 528s - loss: 235.1164 - val_loss: 213.5038
Epoch 30/100
 - 489s - loss: 233.2695 - val_loss: 217.8030
Epoch 31/100
 - 480s - loss: 233.6877 - val_loss: 215.4760
Epoch 32/100
 - 486s - loss: 232.8977 - val_loss: 222.8803
Epoch 33/100
 - 484s - loss: 233.0133 - val_loss: 208.8333
Epoch 34/100
 - 529s - loss: 232.7743 - val_loss: 214.0315
Epoch 35/100
 - 487s - loss: 232.2419 - val_loss: 221.2906
Epoch 36/100
 - 492s - loss: 232.1718 - val_loss: 239.2406
Epoch 37/100
 - 487s - loss: 233.1048 - val_loss: 207.1317
Epoch 38/100
 - 486s - loss: 231.7516 - val_loss: 220.4444
Epoch 39/100
 - 506s - loss: 232.0387 - val_loss: 231.3151
Epoch 40/100
 - 531s - loss: 233.4464 - val_loss: 212.9272
Epoch 41/100
 - 523s - loss: 231.9220 - val_loss: 212.5244
Epoch 42/100
 - 514s - loss: 231.5836 - val_loss: 210.2788
Epoch 43/100
 - 528s - loss: 231.1757 - val_loss: 204.7239
Epoch 44/100
 - 513s - loss: 231.2841 - val_loss: 215.1078
Epoch 45/100
 - 504s - loss: 231.5846 - val_loss: 206.7675
Epoch 46/100
 - 514s - loss: 231.9495 - val_loss: 210.1232
Epoch 47/100
 - 503s - loss: 231.2439 - val_loss: 205.7875
Epoch 48/100
 - 513s - loss: 231.9112 - val_loss: 206.4179
Epoch 49/100
 - 512s - loss: 231.2637 - val_loss: 211.8727
Epoch 50/100
 - 492s - loss: 231.2634 - val_loss: 205.8535
Epoch 51/100
 - 492s - loss: 231.3690 - val_loss: 206.5284
Epoch 52/100
 - 472s - loss: 231.1957 - val_loss: 216.9420
Epoch 53/100
 - 492s - loss: 230.7963 - val_loss: 215.7736
/pkg/python/3.6.1-centos7/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Done with trial 5
