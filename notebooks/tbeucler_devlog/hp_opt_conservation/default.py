default_params = {
    'num_layers':5,
    'layer_0': 512,
    'layer_1': 512,
    'layer_2': 512,
    'layer_3': 512,
    'layer_4': 512,
    'layer_5': 512,
    'layer_6': 512,
    'layer_7': 512,
    'layer_8': 512,
    'alpha': .1,
    'loss_type': 'weak_loss',
    'dropout': 0.25,
    'batch_norm': 1,
    'leaky_relu': .3,
    'lr': 0.001,
    'conservation': 0,
}
